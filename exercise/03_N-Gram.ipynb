{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x268c5575b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "context_size = 2\n",
    "embedding_dim = 10\n",
    "\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "\n",
    "print(len(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege'), (['shall', 'besiege'], 'thy'), (['besiege', 'thy'], 'brow,'), (['thy', 'brow,'], 'And'), (['brow,', 'And'], 'dig'), (['And', 'dig'], 'deep'), (['dig', 'deep'], 'trenches'), (['deep', 'trenches'], 'in'), (['trenches', 'in'], 'thy'), (['in', 'thy'], \"beauty's\"), (['thy', \"beauty's\"], 'field,'), ([\"beauty's\", 'field,'], 'Thy'), (['field,', 'Thy'], \"youth's\"), (['Thy', \"youth's\"], 'proud'), ([\"youth's\", 'proud'], 'livery'), (['proud', 'livery'], 'so'), (['livery', 'so'], 'gazed'), (['so', 'gazed'], 'on'), (['gazed', 'on'], 'now,'), (['on', 'now,'], 'Will'), (['now,', 'Will'], 'be'), (['Will', 'be'], 'a'), (['be', 'a'], \"totter'd\"), (['a', \"totter'd\"], 'weed'), ([\"totter'd\", 'weed'], 'of'), (['weed', 'of'], 'small'), (['of', 'small'], 'worth'), (['small', 'worth'], 'held:'), (['worth', 'held:'], 'Then'), (['held:', 'Then'], 'being'), (['Then', 'being'], 'asked,'), (['being', 'asked,'], 'where'), (['asked,', 'where'], 'all'), (['where', 'all'], 'thy'), (['all', 'thy'], 'beauty'), (['thy', 'beauty'], 'lies,'), (['beauty', 'lies,'], 'Where'), (['lies,', 'Where'], 'all'), (['Where', 'all'], 'the'), (['all', 'the'], 'treasure'), (['the', 'treasure'], 'of'), (['treasure', 'of'], 'thy'), (['of', 'thy'], 'lusty'), (['thy', 'lusty'], 'days;'), (['lusty', 'days;'], 'To'), (['days;', 'To'], 'say,'), (['To', 'say,'], 'within'), (['say,', 'within'], 'thine'), (['within', 'thine'], 'own'), (['thine', 'own'], 'deep'), (['own', 'deep'], 'sunken'), (['deep', 'sunken'], 'eyes,'), (['sunken', 'eyes,'], 'Were'), (['eyes,', 'Were'], 'an'), (['Were', 'an'], 'all-eating'), (['an', 'all-eating'], 'shame,'), (['all-eating', 'shame,'], 'and'), (['shame,', 'and'], 'thriftless'), (['and', 'thriftless'], 'praise.'), (['thriftless', 'praise.'], 'How'), (['praise.', 'How'], 'much'), (['How', 'much'], 'more'), (['much', 'more'], 'praise'), (['more', 'praise'], \"deserv'd\"), (['praise', \"deserv'd\"], 'thy'), ([\"deserv'd\", 'thy'], \"beauty's\"), (['thy', \"beauty's\"], 'use,'), ([\"beauty's\", 'use,'], 'If'), (['use,', 'If'], 'thou'), (['If', 'thou'], 'couldst'), (['thou', 'couldst'], 'answer'), (['couldst', 'answer'], \"'This\"), (['answer', \"'This\"], 'fair'), ([\"'This\", 'fair'], 'child'), (['fair', 'child'], 'of'), (['child', 'of'], 'mine'), (['of', 'mine'], 'Shall'), (['mine', 'Shall'], 'sum'), (['Shall', 'sum'], 'my'), (['sum', 'my'], 'count,'), (['my', 'count,'], 'and'), (['count,', 'and'], 'make'), (['and', 'make'], 'my'), (['make', 'my'], 'old'), (['my', 'old'], \"excuse,'\"), (['old', \"excuse,'\"], 'Proving'), ([\"excuse,'\", 'Proving'], 'his'), (['Proving', 'his'], 'beauty'), (['his', 'beauty'], 'by'), (['beauty', 'by'], 'succession'), (['by', 'succession'], 'thine!'), (['succession', 'thine!'], 'This'), (['thine!', 'This'], 'were'), (['This', 'were'], 'to'), (['were', 'to'], 'be'), (['to', 'be'], 'new'), (['be', 'new'], 'made'), (['new', 'made'], 'when'), (['made', 'when'], 'thou'), (['when', 'thou'], 'art'), (['thou', 'art'], 'old,'), (['art', 'old,'], 'And'), (['old,', 'And'], 'see'), (['And', 'see'], 'thy'), (['see', 'thy'], 'blood'), (['thy', 'blood'], 'warm'), (['blood', 'warm'], 'when'), (['warm', 'when'], 'thou'), (['when', 'thou'], \"feel'st\"), (['thou', \"feel'st\"], 'it'), ([\"feel'st\", 'it'], 'cold.')]\n"
     ]
    }
   ],
   "source": [
    "# context_size=2이므로 앞 두 단어가 주어졌을 때 세번째 단어를 예측하는 작업\n",
    "trigrams = [([test_sentence[i], test_sentence[i+1]], test_sentence[i+2])\n",
    "           for i in range(len(test_sentence)-2)]\n",
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'This': 0, 'an': 1, 'the': 2, 'thriftless': 3, 'thy': 4, 'Where': 5, 'warm': 6, 'see': 7, 'worth': 8, 'trenches': 9, 'deep': 10, \"feel'st\": 11, 'lies,': 12, 'much': 13, 'Thy': 14, 'all-eating': 15, 'cold.': 16, 'Were': 17, \"totter'd\": 18, 'And': 19, 'fair': 20, 'use,': 21, 'sunken': 22, 'days;': 23, 'old,': 24, 'besiege': 25, 'lusty': 26, 'couldst': 27, 'blood': 28, 'shame,': 29, 'praise': 30, 'own': 31, 'being': 32, 'If': 33, 'thine': 34, 'made': 35, 'on': 36, 'where': 37, 'more': 38, 'in': 39, 'proud': 40, 'small': 41, 'to': 42, \"beauty's\": 43, 'new': 44, 'by': 45, \"'This\": 46, 'a': 47, 'asked,': 48, 'livery': 49, 'beauty': 50, 'gazed': 51, 'praise.': 52, 'answer': 53, 'weed': 54, \"youth's\": 55, 'count,': 56, 'thou': 57, 'his': 58, 'dig': 59, 'when': 60, \"excuse,'\": 61, 'held:': 62, 'say,': 63, 'so': 64, 'mine': 65, 'How': 66, 'my': 67, 'were': 68, 'of': 69, 'To': 70, 'Proving': 71, 'child': 72, 'treasure': 73, 'succession': 74, 'field,': 75, 'eyes,': 76, 'Will': 77, 'old': 78, 'all': 79, \"deserv'd\": 80, 'brow,': 81, 'and': 82, 'shall': 83, 'sum': 84, 'art': 85, 'it': 86, 'forty': 87, 'Then': 88, 'When': 89, 'winters': 90, 'make': 91, 'be': 92, 'now,': 93, 'thine!': 94, 'Shall': 95, 'within': 96}\n"
     ]
    }
   ],
   "source": [
    "vocab = set(test_sentence)\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel(nn.Module):\n",
    "    # vocab_size: 총 단어의 갯수\n",
    "    # embedding_dim: embedding output의 차원\n",
    "    # context_size: 총 몇 개의 input을 가지고 output을 도출?\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size*embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeded = self.embedding(x).view(1, -1)\n",
    "        out = F.relu(self.linear1(embeded))\n",
    "        out = self.linear2(out)\n",
    "        prob = F.log_softmax(out, dim=1)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGramModel(\n",
      "  (embedding): Embedding(97, 10)\n",
      "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=97, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "model = NGramModel(len(vocab), embedding_dim, context_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] loss:2.550497\n",
      "[2/10] loss:2.316757\n",
      "[3/10] loss:2.085636\n",
      "[4/10] loss:1.861997\n",
      "[5/10] loss:1.650320\n",
      "[6/10] loss:1.454676\n",
      "[7/10] loss:1.277305\n",
      "[8/10] loss:1.119649\n",
      "[9/10] loss:0.981355\n",
      "[10/10] loss:0.860985\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for context, target  in trigrams:\n",
    "        # input(context)을 word2idx을 이용해 모델로 넘겨줄 작업\n",
    "        context_idxs = [word2idx[w] for w in context]\n",
    "        context_idxs = torch.tensor(context_idxs, dtype=torch.long)\n",
    "        target = torch.tensor([word2idx[target]], dtype=torch.long)\n",
    "        \n",
    "#         print(context_idxs.shape)\n",
    "#         print(target.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(context_idxs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    print(\"[%d/%d] loss:%3f\" % (epoch+1, 10, np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
