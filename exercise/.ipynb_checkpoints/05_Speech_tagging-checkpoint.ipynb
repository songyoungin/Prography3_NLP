{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c162743a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(3, 3)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 3\n",
    "output_dim = 3\n",
    "lstm = nn.LSTM(input_dim, output_dim)\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.9999, -1.6476,  0.8098]]), tensor([[ 0.0554,  1.1340, -0.5326]]), tensor([[ 0.6592, -1.5964, -0.3769]]), tensor([[-3.1020, -0.0995, -0.7213]]), tensor([[ 1.2708, -0.0020, -1.0952]])]\n"
     ]
    }
   ],
   "source": [
    "# sequence 생성\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
    "\n",
    "# 한번에 하나의 단어만 lstm에 투입\n",
    "for i in inputs:\n",
    "    print(i.shape)\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 한꺼번에 sequence 전체를 lstm에 투입\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "print(inputs.shape)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2763,  0.2370, -0.2530]],\n",
      "\n",
      "        [[-0.1142,  0.3029, -0.1229]],\n",
      "\n",
      "        [[-0.2502,  0.0923, -0.2127]],\n",
      "\n",
      "        [[-0.0960,  0.0908, -0.1823]],\n",
      "\n",
      "        [[-0.0137,  0.0445, -0.1324]]])\n",
      "(tensor([[[-0.0137,  0.0445, -0.1324]]]), tensor([[[-0.0331,  0.1168, -0.4049]]]))\n"
     ]
    }
   ],
   "source": [
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An LSTM for Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepard data\n",
    "# sequence vector to indexs vector\n",
    "def prepare_sequence(seq, word2idx):\n",
    "    idxs = [word2idx[w] for w in seq]\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "# input: 문장의 token\n",
    "# target: token들의 품사\n",
    "train_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "word2idx = {}\n",
    "for sentence, tag in train_data:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "print(word2idx)\n",
    "\n",
    "tag2idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 6\n",
    "hidden_dim = 6\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(tag2idx)\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger,self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # num_layers, minibatch_size, hidden_dim\n",
    "        return (torch.zeros(1, 1, self.hidden_dim), torch.zeros(1, 1, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(\"Original input size:\", x.shape)\n",
    "        emb = self.embedding(x)\n",
    "#         print(\"Embedding output size:\", emb.shape)\n",
    "        emb = emb.view(len(x), 1, -1) \n",
    "#         print(\"Resized embedding output size:\", emb.shape)\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(emb.view(len(x), 1, -1), self.hidden)\n",
    "        tag_out = self.hidden2tag(lstm_out.view(len(x), -1))\n",
    "        out = F.log_softmax(tag_out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTagger(\n",
      "  (embedding): Embedding(9, 6)\n",
      "  (lstm): LSTM(6, 6)\n",
      "  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0118, -1.3521, -0.9735],\n",
      "        [-1.0225, -1.2918, -1.0065],\n",
      "        [-1.0567, -1.2470, -1.0077],\n",
      "        [-1.0860, -1.1678, -1.0459],\n",
      "        [-1.0265, -1.2483, -1.0363]])\n"
     ]
    }
   ],
   "source": [
    "# 학습 전의 output 확인\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(train_data[0][0], word2idx)\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/300] loss:1.153\n",
      "[2/300] loss:1.141\n",
      "[3/300] loss:1.130\n",
      "[4/300] loss:1.120\n",
      "[5/300] loss:1.112\n",
      "[6/300] loss:1.105\n",
      "[7/300] loss:1.098\n",
      "[8/300] loss:1.092\n",
      "[9/300] loss:1.087\n",
      "[10/300] loss:1.082\n",
      "[11/300] loss:1.078\n",
      "[12/300] loss:1.074\n",
      "[13/300] loss:1.071\n",
      "[14/300] loss:1.068\n",
      "[15/300] loss:1.065\n",
      "[16/300] loss:1.063\n",
      "[17/300] loss:1.060\n",
      "[18/300] loss:1.058\n",
      "[19/300] loss:1.056\n",
      "[20/300] loss:1.054\n",
      "[21/300] loss:1.052\n",
      "[22/300] loss:1.050\n",
      "[23/300] loss:1.049\n",
      "[24/300] loss:1.047\n",
      "[25/300] loss:1.046\n",
      "[26/300] loss:1.044\n",
      "[27/300] loss:1.043\n",
      "[28/300] loss:1.041\n",
      "[29/300] loss:1.040\n",
      "[30/300] loss:1.038\n",
      "[31/300] loss:1.037\n",
      "[32/300] loss:1.036\n",
      "[33/300] loss:1.034\n",
      "[34/300] loss:1.033\n",
      "[35/300] loss:1.031\n",
      "[36/300] loss:1.030\n",
      "[37/300] loss:1.028\n",
      "[38/300] loss:1.027\n",
      "[39/300] loss:1.026\n",
      "[40/300] loss:1.024\n",
      "[41/300] loss:1.023\n",
      "[42/300] loss:1.021\n",
      "[43/300] loss:1.019\n",
      "[44/300] loss:1.018\n",
      "[45/300] loss:1.016\n",
      "[46/300] loss:1.015\n",
      "[47/300] loss:1.013\n",
      "[48/300] loss:1.011\n",
      "[49/300] loss:1.010\n",
      "[50/300] loss:1.008\n",
      "[51/300] loss:1.006\n",
      "[52/300] loss:1.004\n",
      "[53/300] loss:1.002\n",
      "[54/300] loss:1.000\n",
      "[55/300] loss:0.998\n",
      "[56/300] loss:0.996\n",
      "[57/300] loss:0.994\n",
      "[58/300] loss:0.992\n",
      "[59/300] loss:0.990\n",
      "[60/300] loss:0.988\n",
      "[61/300] loss:0.986\n",
      "[62/300] loss:0.983\n",
      "[63/300] loss:0.981\n",
      "[64/300] loss:0.978\n",
      "[65/300] loss:0.976\n",
      "[66/300] loss:0.973\n",
      "[67/300] loss:0.971\n",
      "[68/300] loss:0.968\n",
      "[69/300] loss:0.965\n",
      "[70/300] loss:0.963\n",
      "[71/300] loss:0.960\n",
      "[72/300] loss:0.957\n",
      "[73/300] loss:0.954\n",
      "[74/300] loss:0.951\n",
      "[75/300] loss:0.948\n",
      "[76/300] loss:0.945\n",
      "[77/300] loss:0.941\n",
      "[78/300] loss:0.938\n",
      "[79/300] loss:0.934\n",
      "[80/300] loss:0.931\n",
      "[81/300] loss:0.927\n",
      "[82/300] loss:0.924\n",
      "[83/300] loss:0.920\n",
      "[84/300] loss:0.916\n",
      "[85/300] loss:0.912\n",
      "[86/300] loss:0.908\n",
      "[87/300] loss:0.904\n",
      "[88/300] loss:0.900\n",
      "[89/300] loss:0.895\n",
      "[90/300] loss:0.891\n",
      "[91/300] loss:0.887\n",
      "[92/300] loss:0.882\n",
      "[93/300] loss:0.877\n",
      "[94/300] loss:0.873\n",
      "[95/300] loss:0.868\n",
      "[96/300] loss:0.863\n",
      "[97/300] loss:0.858\n",
      "[98/300] loss:0.853\n",
      "[99/300] loss:0.847\n",
      "[100/300] loss:0.842\n",
      "[101/300] loss:0.836\n",
      "[102/300] loss:0.831\n",
      "[103/300] loss:0.825\n",
      "[104/300] loss:0.819\n",
      "[105/300] loss:0.813\n",
      "[106/300] loss:0.807\n",
      "[107/300] loss:0.801\n",
      "[108/300] loss:0.795\n",
      "[109/300] loss:0.789\n",
      "[110/300] loss:0.782\n",
      "[111/300] loss:0.776\n",
      "[112/300] loss:0.769\n",
      "[113/300] loss:0.763\n",
      "[114/300] loss:0.756\n",
      "[115/300] loss:0.749\n",
      "[116/300] loss:0.742\n",
      "[117/300] loss:0.735\n",
      "[118/300] loss:0.728\n",
      "[119/300] loss:0.720\n",
      "[120/300] loss:0.713\n",
      "[121/300] loss:0.706\n",
      "[122/300] loss:0.698\n",
      "[123/300] loss:0.691\n",
      "[124/300] loss:0.683\n",
      "[125/300] loss:0.676\n",
      "[126/300] loss:0.668\n",
      "[127/300] loss:0.660\n",
      "[128/300] loss:0.652\n",
      "[129/300] loss:0.645\n",
      "[130/300] loss:0.637\n",
      "[131/300] loss:0.629\n",
      "[132/300] loss:0.621\n",
      "[133/300] loss:0.613\n",
      "[134/300] loss:0.605\n",
      "[135/300] loss:0.597\n",
      "[136/300] loss:0.590\n",
      "[137/300] loss:0.582\n",
      "[138/300] loss:0.574\n",
      "[139/300] loss:0.566\n",
      "[140/300] loss:0.559\n",
      "[141/300] loss:0.551\n",
      "[142/300] loss:0.544\n",
      "[143/300] loss:0.536\n",
      "[144/300] loss:0.529\n",
      "[145/300] loss:0.521\n",
      "[146/300] loss:0.514\n",
      "[147/300] loss:0.507\n",
      "[148/300] loss:0.500\n",
      "[149/300] loss:0.493\n",
      "[150/300] loss:0.486\n",
      "[151/300] loss:0.480\n",
      "[152/300] loss:0.473\n",
      "[153/300] loss:0.467\n",
      "[154/300] loss:0.460\n",
      "[155/300] loss:0.454\n",
      "[156/300] loss:0.448\n",
      "[157/300] loss:0.442\n",
      "[158/300] loss:0.436\n",
      "[159/300] loss:0.430\n",
      "[160/300] loss:0.424\n",
      "[161/300] loss:0.419\n",
      "[162/300] loss:0.413\n",
      "[163/300] loss:0.408\n",
      "[164/300] loss:0.403\n",
      "[165/300] loss:0.398\n",
      "[166/300] loss:0.393\n",
      "[167/300] loss:0.388\n",
      "[168/300] loss:0.383\n",
      "[169/300] loss:0.378\n",
      "[170/300] loss:0.373\n",
      "[171/300] loss:0.369\n",
      "[172/300] loss:0.364\n",
      "[173/300] loss:0.360\n",
      "[174/300] loss:0.356\n",
      "[175/300] loss:0.352\n",
      "[176/300] loss:0.347\n",
      "[177/300] loss:0.343\n",
      "[178/300] loss:0.339\n",
      "[179/300] loss:0.336\n",
      "[180/300] loss:0.332\n",
      "[181/300] loss:0.328\n",
      "[182/300] loss:0.324\n",
      "[183/300] loss:0.321\n",
      "[184/300] loss:0.317\n",
      "[185/300] loss:0.314\n",
      "[186/300] loss:0.310\n",
      "[187/300] loss:0.307\n",
      "[188/300] loss:0.304\n",
      "[189/300] loss:0.300\n",
      "[190/300] loss:0.297\n",
      "[191/300] loss:0.294\n",
      "[192/300] loss:0.291\n",
      "[193/300] loss:0.288\n",
      "[194/300] loss:0.285\n",
      "[195/300] loss:0.282\n",
      "[196/300] loss:0.279\n",
      "[197/300] loss:0.276\n",
      "[198/300] loss:0.273\n",
      "[199/300] loss:0.270\n",
      "[200/300] loss:0.268\n",
      "[201/300] loss:0.265\n",
      "[202/300] loss:0.262\n",
      "[203/300] loss:0.259\n",
      "[204/300] loss:0.257\n",
      "[205/300] loss:0.254\n",
      "[206/300] loss:0.252\n",
      "[207/300] loss:0.249\n",
      "[208/300] loss:0.246\n",
      "[209/300] loss:0.244\n",
      "[210/300] loss:0.241\n",
      "[211/300] loss:0.239\n",
      "[212/300] loss:0.237\n",
      "[213/300] loss:0.234\n",
      "[214/300] loss:0.232\n",
      "[215/300] loss:0.229\n",
      "[216/300] loss:0.227\n",
      "[217/300] loss:0.225\n",
      "[218/300] loss:0.222\n",
      "[219/300] loss:0.220\n",
      "[220/300] loss:0.218\n",
      "[221/300] loss:0.216\n",
      "[222/300] loss:0.213\n",
      "[223/300] loss:0.211\n",
      "[224/300] loss:0.209\n",
      "[225/300] loss:0.207\n",
      "[226/300] loss:0.205\n",
      "[227/300] loss:0.203\n",
      "[228/300] loss:0.200\n",
      "[229/300] loss:0.198\n",
      "[230/300] loss:0.196\n",
      "[231/300] loss:0.194\n",
      "[232/300] loss:0.192\n",
      "[233/300] loss:0.190\n",
      "[234/300] loss:0.188\n",
      "[235/300] loss:0.186\n",
      "[236/300] loss:0.184\n",
      "[237/300] loss:0.182\n",
      "[238/300] loss:0.180\n",
      "[239/300] loss:0.178\n",
      "[240/300] loss:0.176\n",
      "[241/300] loss:0.175\n",
      "[242/300] loss:0.173\n",
      "[243/300] loss:0.171\n",
      "[244/300] loss:0.169\n",
      "[245/300] loss:0.167\n",
      "[246/300] loss:0.165\n",
      "[247/300] loss:0.164\n",
      "[248/300] loss:0.162\n",
      "[249/300] loss:0.160\n",
      "[250/300] loss:0.159\n",
      "[251/300] loss:0.157\n",
      "[252/300] loss:0.155\n",
      "[253/300] loss:0.154\n",
      "[254/300] loss:0.152\n",
      "[255/300] loss:0.150\n",
      "[256/300] loss:0.149\n",
      "[257/300] loss:0.147\n",
      "[258/300] loss:0.146\n",
      "[259/300] loss:0.144\n",
      "[260/300] loss:0.142\n",
      "[261/300] loss:0.141\n",
      "[262/300] loss:0.139\n",
      "[263/300] loss:0.138\n",
      "[264/300] loss:0.137\n",
      "[265/300] loss:0.135\n",
      "[266/300] loss:0.134\n",
      "[267/300] loss:0.132\n",
      "[268/300] loss:0.131\n",
      "[269/300] loss:0.130\n",
      "[270/300] loss:0.128\n",
      "[271/300] loss:0.127\n",
      "[272/300] loss:0.126\n",
      "[273/300] loss:0.124\n",
      "[274/300] loss:0.123\n",
      "[275/300] loss:0.122\n",
      "[276/300] loss:0.121\n",
      "[277/300] loss:0.119\n",
      "[278/300] loss:0.118\n",
      "[279/300] loss:0.117\n",
      "[280/300] loss:0.116\n",
      "[281/300] loss:0.115\n",
      "[282/300] loss:0.113\n",
      "[283/300] loss:0.112\n",
      "[284/300] loss:0.111\n",
      "[285/300] loss:0.110\n",
      "[286/300] loss:0.109\n",
      "[287/300] loss:0.108\n",
      "[288/300] loss:0.107\n",
      "[289/300] loss:0.106\n",
      "[290/300] loss:0.105\n",
      "[291/300] loss:0.104\n",
      "[292/300] loss:0.103\n",
      "[293/300] loss:0.102\n",
      "[294/300] loss:0.101\n",
      "[295/300] loss:0.100\n",
      "[296/300] loss:0.099\n",
      "[297/300] loss:0.098\n",
      "[298/300] loss:0.097\n",
      "[299/300] loss:0.096\n",
      "[300/300] loss:0.095\n"
     ]
    }
   ],
   "source": [
    "# 학습 과정\n",
    "import numpy as np\n",
    "for epoch in range(300):\n",
    "    losses = []\n",
    "    for sentence, tags in train_data:\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        sentence = prepare_sequence(sentence, word2idx)\n",
    "        tags = prepare_sequence(tags, tag2idx)\n",
    "        \n",
    "#         print(sentence.shape)\n",
    "#         print(tags.shape)\n",
    "        \n",
    "        outputs = model(sentence)\n",
    "        loss = criterion(outputs, tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    print(\"[%d/%d] loss:%.3f\" % (epoch+1, 300, np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2016, -2.6027, -2.2211],\n",
      "        [-4.7044, -0.0215, -4.4085],\n",
      "        [-1.5090, -1.9637, -0.4486],\n",
      "        [-0.0980, -4.1194, -2.5625],\n",
      "        [-4.5778, -0.0152, -5.3282]])\n"
     ]
    }
   ],
   "source": [
    "# 학습 후의 output 확인\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(train_data[0][0], word2idx)\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'boy', 'goes', 'to', 'high', 'school']\n",
      "['DET', 'NN', 'V', 'DET', 'NN', 'NN']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_sentence = \"The boy goes to high school\"\n",
    "test_sentence = test_sentence.split()\n",
    "\n",
    "print(test_sentence)\n",
    "\n",
    "word2idx = {}\n",
    "for word in test_sentence:\n",
    "    if word not in word2idx:\n",
    "        word2idx[word] = len(word2idx)\n",
    "    \n",
    "tag2idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "\n",
    "test_sentence = prepare_sequence(test_sentence, word2idx)\n",
    "outputs = model(test_sentence)\n",
    "scores, idxs = torch.max(outputs, dim=1)\n",
    "result_tag = [idx2tag[idx.item()] for idx in idxs]\n",
    "print(result_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
