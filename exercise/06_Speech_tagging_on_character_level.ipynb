{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "char2idx = {}\n",
    "\n",
    "def prepare_char_seq(word, char2idx):\n",
    "    idxs = []\n",
    "    for char in word:\n",
    "        idxs.append(char2idx[char])\n",
    "        \n",
    "    return idxs\n",
    "\n",
    "def prepare_seq(seq, word2idx, char2idx):\n",
    "    idxs = []\n",
    "    for word in seq:\n",
    "        idxs.append((word2idx[word], prepare_char_seq(word, char2idx)))\n",
    "    \n",
    "    return idxs\n",
    "\n",
    "def preprare_tag(tag, tag2idx):\n",
    "    idxs = []\n",
    "    for t in tag:\n",
    "        idxs.append(tag2idx[t])\n",
    "    \n",
    "    return torch.LongTensor(idxs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n",
      "{'T': 0, 'h': 1, 'e': 2, 'd': 3, 'o': 4, 'g': 5, 'a': 6, 't': 7, 'p': 8, 'l': 9, 'E': 10, 'v': 11, 'r': 12, 'y': 13, 'b': 14, 'k': 15}\n"
     ]
    }
   ],
   "source": [
    "for sent, tags in train_data:\n",
    "    for word in sent:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "        for char in word:\n",
    "            if char not in char2idx:\n",
    "                char2idx[char] = len(char2idx)\n",
    "                \n",
    "print(word2idx)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DET': 0, 'NN': 1, 'V': 2}\n",
      "{0: 'DET', 1: 'NN', 2: 'V'}\n"
     ]
    }
   ],
   "source": [
    "tag2idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}\n",
    "\n",
    "print(tag2idx)\n",
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding_dim = 3\n",
    "char_hidden_dim = 3\n",
    "\n",
    "word_embedding_dim = 6\n",
    "hidden_dim = 6\n",
    "\n",
    "word_vocab_size = len(word2idx)\n",
    "char_vocab_size = len(char2idx)\n",
    "tagset_size = len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, word_embedding_dim, char_embedding_dim, \n",
    "                 hidden_dim, char_hidden_dim,\n",
    "                word_vocab_size, char_vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.char_embedding_dim = char_embedding_dim\n",
    "        \n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_embedding_dim)\n",
    "        self.char_lstm = nn.LSTM(char_embedding_dim, char_hidden_dim)\n",
    "        \n",
    "        self.word_embedding = nn.Embedding(word_vocab_size, word_embedding_dim)\n",
    "        self.word_lstm = nn.LSTM(word_embedding_dim + char_hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "        self.hidden = self.init_hidden(hidden_dim)\n",
    "        self.char_hidden = self.init_hidden(char_hidden_dim)\n",
    "        \n",
    "    def init_hidden(self, dim):\n",
    "        return (torch.zeros(1, 1, dim).to(device),\n",
    "                torch.zeros(1, 1, dim).to(device))\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        word_idxs = []\n",
    "        char_lstm_result = []\n",
    "        for word in sentence:\n",
    "            words = word[0]\n",
    "            chars = word[1]\n",
    "            \n",
    "            # init character hidden\n",
    "            self.char_hidden = self.init_hidden(char_hidden_dim)\n",
    "            \n",
    "            word_idxs.append(words)\n",
    "            char_idx = torch.LongTensor(chars).to(device)\n",
    "            \n",
    "            char_emb_out = self.char_embedding(char_idx)\n",
    "            char_emb_out = char_emb_out.view(len(chars), 1, self.char_embedding_dim)\n",
    "            \n",
    "            char_lstm_out, self.char_hidden = self.char_lstm(char_emb_out, self.char_hidden)\n",
    "            char_lstm_result.append(char_lstm_out[-1])\n",
    "    \n",
    "        char_lstm_result = torch.stack(char_lstm_result)\n",
    "            \n",
    "        word_idxs = torch.LongTensor(word_idxs).to(device)\n",
    "        \n",
    "        word_emb_out = self.word_embedding(word_idxs)\n",
    "        word_emb_out = word_emb_out.view(len(sentence), 1, self.word_embedding_dim)\n",
    "        \n",
    "        lstm_in = torch.cat((word_emb_out, char_lstm_result), dim=2)\n",
    "        lstm_out, self.hidden = self.word_lstm(lstm_in, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), -1)\n",
    "        \n",
    "        tag = self.hidden2tag(lstm_out)\n",
    "        out = F.log_softmax(tag)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTagger(\n",
      "  (char_embedding): Embedding(16, 3)\n",
      "  (char_lstm): LSTM(3, 3)\n",
      "  (word_embedding): Embedding(9, 6)\n",
      "  (word_lstm): LSTM(9, 6)\n",
      "  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(word_embedding_dim, char_embedding_dim,\n",
    "                   hidden_dim, char_hidden_dim,\n",
    "                   word_vocab_size, char_vocab_size, tagset_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/1000] loss:0.962\n",
      "[60/1000] loss:0.797\n",
      "[90/1000] loss:0.536\n",
      "[120/1000] loss:0.286\n",
      "[150/1000] loss:0.159\n",
      "[180/1000] loss:0.100\n",
      "[210/1000] loss:0.070\n",
      "[240/1000] loss:0.052\n",
      "[270/1000] loss:0.041\n",
      "[300/1000] loss:0.033\n",
      "[330/1000] loss:0.028\n",
      "[360/1000] loss:0.024\n",
      "[390/1000] loss:0.021\n",
      "[420/1000] loss:0.019\n",
      "[450/1000] loss:0.017\n",
      "[480/1000] loss:0.015\n",
      "[510/1000] loss:0.014\n",
      "[540/1000] loss:0.013\n",
      "[570/1000] loss:0.012\n",
      "[600/1000] loss:0.011\n",
      "[630/1000] loss:0.010\n",
      "[660/1000] loss:0.010\n",
      "[690/1000] loss:0.009\n",
      "[720/1000] loss:0.008\n",
      "[750/1000] loss:0.008\n",
      "[780/1000] loss:0.008\n",
      "[810/1000] loss:0.007\n",
      "[840/1000] loss:0.007\n",
      "[870/1000] loss:0.007\n",
      "[900/1000] loss:0.006\n",
      "[930/1000] loss:0.006\n",
      "[960/1000] loss:0.006\n",
      "[990/1000] loss:0.006\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for step, (sentence, tags) in enumerate(train_data):\n",
    "        \n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden(hidden_dim)\n",
    "            \n",
    "        inputs = prepare_seq(sentence, word2idx, char2idx)\n",
    "        targets = preprare_tag(tags, tag2idx)\n",
    "\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1)% 30 == 0:\n",
    "        print(\"[%d/%d] loss:%.3f\" % (epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save complete!\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"speech_tag.pth\")\n",
    "print(\"model save complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Everybody': 0, 'read': 1, 'that': 2, 'book': 3}\n",
      "{'E': 0, 'v': 1, 'e': 2, 'r': 3, 'y': 4, 'b': 5, 'o': 6, 'd': 7, 'a': 8, 't': 9, 'h': 10, 'k': 11}\n",
      "tensor([[-0.0329, -3.4346, -8.7481],\n",
      "        [-6.6603, -0.0021, -7.0842],\n",
      "        [-7.3668, -5.4001, -0.0052],\n",
      "        [-0.0042, -6.0834, -6.2607]])\n",
      "tensor(1.00000e-02 *\n",
      "       [-3.2935, -0.2121, -0.5161, -0.4199]) tensor([ 0,  1,  2,  0])\n",
      "['DET', 'NN', 'V', 'DET']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_data = \"Everybody read that book\".split()\n",
    "test_word2idx = {}\n",
    "test_char2idx = {}\n",
    "\n",
    "for word in test_data:\n",
    "    if word not in test_word2idx:\n",
    "        test_word2idx[word] = len(test_word2idx)\n",
    "    for char in word:\n",
    "        if char not in test_char2idx:\n",
    "            test_char2idx[char] = len(test_char2idx)\n",
    "print(test_word2idx)\n",
    "print(test_char2idx)\n",
    "\n",
    "test_input = prepare_seq(test_data, test_word2idx, test_char2idx)\n",
    "test_output = model(test_input)\n",
    "\n",
    "print(test_output)\n",
    "\n",
    "score, idx = torch.max(test_output, dim=1)\n",
    "print(score, idx)\n",
    "\n",
    "result = [idx2tag[i.item()] for i in idx]\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
